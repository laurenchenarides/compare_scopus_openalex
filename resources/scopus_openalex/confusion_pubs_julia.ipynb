{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49982df-0aff-4eef-b2c1-16c3605dbda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\AppData\\Local\\Temp\\ipykernel_9452\\2659123430.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#import pymongo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71531d8-21a1-460f-ae9d-9d5cf198414c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Connect to the local MongoDB instance\n",
    "# client = pymongo.MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a82859d-b209-4e5f-a465-8f5f7d3c72e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Access the 'dd-usda' database\n",
    "# db = client['dd-usda']\n",
    "\n",
    "# # Access the 'publications' collection\n",
    "# collection = db['publications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09859037-2ed5-446f-868e-624f21324607",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Define the query parameters\n",
    "# query = {\n",
    "#     'author_american': True,\n",
    "#     '$or': [\n",
    "#         {\n",
    "#             'aliases': {\n",
    "#                 '$in': [\n",
    "#                     \"USDA\", \"USDA Census\", \"US Department of Agriculture\",\n",
    "#                     \"United States Department of Agriculture\", \"NASS\", \"NASS Census of Agriculture\"\n",
    "#                 ]\n",
    "#             }\n",
    "#         },\n",
    "#         {\n",
    "#             'second_alias': {\n",
    "#                 '$in': [\n",
    "#                     \"USDA\", \"USDA Census\", \"US Department of Agriculture\",\n",
    "#                     \"United States Department of Agriculture\", \"NASS\", \"NASS Census of Agriculture\"\n",
    "#                 ]\n",
    "#             }\n",
    "#         }\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895c2a44-26b4-4584-b975-0b531e3f28b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Execute the query\n",
    "# projection = {\n",
    "#     'name': 1,\n",
    "#     'doi': 1,\n",
    "#     'year': 1,\n",
    "#     '_id': 0  # Exclude '_id' if you don't need it\n",
    "# }\n",
    "# cursor = collection.find(query, projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3564233-02c7-426c-871d-03529d0a29e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert cursor to list\n",
    "# documents = list(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d708837c-4b51-48bd-b5b7-ff45e7b6399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openalex_pubs_pubs = pd.read_csv(\"openalex_pubs_pubs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd154b00-36b6-41dc-be07-8059ae3cce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus_pubs = pd.read_csv('scopus_pubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e37393-7acd-4044-baf6-d8e5825c50b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         doi  \\\n",
      "0   https://doi.org/10.1175/WCAS-D-17-0067.1   \n",
      "1  https://doi.org/10.1061/9780784481400.026   \n",
      "2  https://doi.org/10.1186/s13007-018-0338-z   \n",
      "3         https://doi.org/10.1111/anti.12694   \n",
      "4           https://doi.org/10.1111/csp2.489   \n",
      "\n",
      "                                               title  year  \n",
      "0  Tracking drought perspectives: A rural case st...  2018  \n",
      "1   A Critical Analysis of the Lake Champlain's TMDL  2018  \n",
      "2  Remote estimation of rapeseed yield with unman...  2018  \n",
      "3  Pathogenic Metabolisms: A Rift and the Zika Vi...  2021  \n",
      "4  Exploring pathways to participation in an at-r...  2021  \n"
     ]
    }
   ],
   "source": [
    "scopus_pubs['doi'] = 'https://doi.org/' + scopus_pubs['doi'].astype(str)\n",
    "print(scopus_pubs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6fa9a5d-2ac4-4541-b7ad-f6a7a3014ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0           0  Research topics to scale up cover crop use: Re...   \n",
      "1           1  The Impact of Targeted Data Collection on Nonr...   \n",
      "2           2  Climate change beliefs, risk perceptions, and ...   \n",
      "3           3  National-scale soybean mapping and area estima...   \n",
      "4           4  Measuring land-use and land-cover change using...   \n",
      "\n",
      "                         doi  year  exists_in_openalex  \n",
      "0      10.2489/jswc.72.3.59a  2017                True  \n",
      "1      10.1515/jos-2017-0039  2017                True  \n",
      "2  10.1016/j.crm.2016.11.004  2017                True  \n",
      "3  10.1016/j.rse.2017.01.008  2017                True  \n",
      "4  10.1016/j.jag.2017.06.007  2017                True  \n"
     ]
    }
   ],
   "source": [
    "print(openalex_pubs_pubs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46a8d67-0d02-47b0-97fa-27379ee3cb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  doi  \\\n",
      "0      10.1001/jamadermatol.2022.0136   \n",
      "1   10.1001/jamahealthforum.2023.1672   \n",
      "2   10.1001/jamahealthforum.2023.2247   \n",
      "3  10.1001/jamanetworkopen.2022.30697   \n",
      "4  10.1001/jamanetworkopen.2022.36898   \n",
      "\n",
      "                                               title  year  \\\n",
      "0  Training and Practice Characteristics of Inter...  2022   \n",
      "1  Changes in Self-Reported Adult Health and Hous...  2023   \n",
      "2  Urine Drug Screening in a Telehealth Setting f...  2023   \n",
      "3  Association of Neighborhood Economic Trajector...  2022   \n",
      "4  Association of National Expansion of Insurance...  2022   \n",
      "\n",
      "   exists_in_openalex  exists_in_scopus  \n",
      "0                True             False  \n",
      "1                True             False  \n",
      "2                True             False  \n",
      "3                True             False  \n",
      "4                True             False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\AppData\\Local\\Temp\\ipykernel_9452\\3426958663.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['exists_in_openalex'] = merged_df['exists_in_openalex'].fillna(False)\n",
      "C:\\Users\\rafal\\AppData\\Local\\Temp\\ipykernel_9452\\3426958663.py:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  merged_df['exists_in_scopus'] = merged_df['exists_in_scopus'].fillna(False)\n",
      "C:\\Users\\rafal\\AppData\\Local\\Temp\\ipykernel_9452\\3426958663.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['year'] = final_df['year'].astype('Int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Standardize DOI Columns ---\n",
    "\n",
    "# Remove 'https://doi.org/' prefix and standardize case in 'openalex'\n",
    "openalex_pubs['doi'] = openalex_pubs['doi'].str.strip().str.lower()\n",
    "openalex_pubs['doi'] = openalex_pubs['doi'].str.replace('https://doi.org/', '', regex=False)\n",
    "\n",
    "# Remove 'https://doi.org/' prefix and standardize case in 'scopus'\n",
    "scopus_pubs['doi'] = scopus_pubs['doi'].str.strip().str.lower()\n",
    "scopus_pubs['doi'] = scopus_pubs['doi'].str.replace('https://doi.org/', '', regex=False)\n",
    "\n",
    "# --- Add Indicator Columns ---\n",
    "\n",
    "# 'openalex' indicator\n",
    "openalex_pubs['exists_in_openalex'] = True\n",
    "\n",
    "# 'scopus' indicator\n",
    "scopus_pubs['exists_in_scopus'] = True\n",
    "\n",
    "# --- Rename Columns for Consistency ---\n",
    "\n",
    "# Rename 'name' to 'title' in 'openalex' if necessary\n",
    "if 'name' in openalex_pubs.columns:\n",
    "    openalex_pubs.rename(columns={'name': 'title'}, inplace=True)\n",
    "\n",
    "# --- Merge DataFrames ---\n",
    "\n",
    "# Perform an outer merge on 'doi'\n",
    "merged_df = pd.merge(\n",
    "    openalex_pubs,\n",
    "    scopus_pubs,\n",
    "    on='doi',\n",
    "    how='outer',\n",
    "    suffixes=('_openalex', '_scopus')\n",
    ")\n",
    "\n",
    "# --- Handle Missing Indicator Values ---\n",
    "\n",
    "# Fill NaN values with False\n",
    "merged_df['exists_in_openalex'] = merged_df['exists_in_openalex'].fillna(False)\n",
    "merged_df['exists_in_scopus'] = merged_df['exists_in_scopus'].fillna(False)\n",
    "\n",
    "# --- Consolidate 'title' and 'year' Columns ---\n",
    "\n",
    "# Combine 'title' columns\n",
    "merged_df['title'] = merged_df['title_openalex'].combine_first(merged_df['title_scopus'])\n",
    "\n",
    "# Combine 'year' columns\n",
    "merged_df['year'] = merged_df['year_openalex'].combine_first(merged_df['year_scopus'])\n",
    "\n",
    "# --- Select Desired Columns ---\n",
    "\n",
    "# Create the final DataFrame\n",
    "final_df = merged_df[['doi', 'title', 'year', 'exists_in_openalex', 'exists_in_scopus']]\n",
    "\n",
    "# --- Handle Data Types ---\n",
    "\n",
    "# Convert 'year' to integer type if possible\n",
    "final_df['year'] = final_df['year'].astype('Int64')\n",
    "\n",
    "# --- Verify the Final DataFrame ---\n",
    "\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ad2da5-edb4-4b0e-a03c-b52ee34aaf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped Counts by Year and Source:\n",
      "    year         source  publication_count\n",
      "0   2017           Both                125\n",
      "1   2017    Only Scopus                455\n",
      "2   2017  Only openalex               1147\n",
      "3   2018           Both                161\n",
      "4   2018    Only Scopus                464\n",
      "5   2018  Only openalex               1183\n",
      "6   2019           Both                139\n",
      "7   2019    Only Scopus                583\n",
      "8   2019  Only openalex               1035\n",
      "9   2020           Both                 64\n",
      "10  2020    Only Scopus                644\n",
      "11  2020  Only openalex                578\n",
      "12  2021           Both                 76\n",
      "13  2021    Only Scopus                749\n",
      "14  2021  Only openalex                643\n",
      "15  2022           Both                 54\n",
      "16  2022    Only Scopus                670\n",
      "17  2022  Only openalex                850\n",
      "18  2023           Both                 64\n",
      "19  2023    Only Scopus                466\n",
      "20  2023  Only openalex                941\n",
      "21  2024  Only openalex                331\n",
      "\n",
      "Pivot Table of Counts:\n",
      "source  Both  Only Scopus  Only openalex\n",
      "year                                    \n",
      "2017     125          455           1147\n",
      "2018     161          464           1183\n",
      "2019     139          583           1035\n",
      "2020      64          644            578\n",
      "2021      76          749            643\n",
      "2022      54          670            850\n",
      "2023      64          466            941\n",
      "2024       0            0            331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafal\\AppData\\Local\\Temp\\ipykernel_9452\\276038858.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['source'] = final_df.apply(determine_source, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create 'source' column\n",
    "def determine_source(row):\n",
    "    if row['exists_in_openalex'] and row['exists_in_scopus']:\n",
    "        return 'Both'\n",
    "    elif row['exists_in_openalex']:\n",
    "        return 'Only openalex'\n",
    "    elif row['exists_in_scopus']:\n",
    "        return 'Only Scopus'\n",
    "    else:\n",
    "        return 'Neither'  # Should not happen based on your data\n",
    "\n",
    "final_df['source'] = final_df.apply(determine_source, axis=1)\n",
    "\n",
    "# Step 2: Group by 'year' and 'source' and count\n",
    "counts = final_df.groupby(['year', 'source']).size().reset_index(name='publication_count')\n",
    "\n",
    "# Step 3: Sort and display the counts\n",
    "counts = counts.sort_values(by=['year', 'source'])\n",
    "print(\"Grouped Counts by Year and Source:\")\n",
    "print(counts)\n",
    "\n",
    "# Step 4: Pivot the DataFrame for better visualization\n",
    "pivot_table = counts.pivot(index='year', columns='source', values='publication_count').fillna(0).astype(int)\n",
    "\n",
    "print(\"\\nPivot Table of Counts:\")\n",
    "print(pivot_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
